# Loopa

**Loopa** is a SwiftUI video-editing playground for iOS. Import or capture a video clip, trim it with visual feedback, preview 11 Core Image filters in real-time with animated thumbnails, and export your masterpiece as either a filtered `.mov` video or an animated `.gif` â€“ all on device.

---

## âœ¨ Features

### ğŸ¬ Video Input & Capture
* **Video Import** â€“ Photos-picker integration (`PHPickerViewController`) for one-tap import
* **Camera Capture** â€“ Built-in video recording with `CameraKitView` and `VideoCaptureView`
* **Real-time Preview** â€“ SwiftUI interface with live preview using `AVPlayer`

### ğŸ¨ Visual Effects & Editing
* **11 Built-in Filters** â€“ Comprehensive filter set powered by Core Image:
  - None, Sepia, Comic, Posterize, Noir, Mono, Blur, Vignette, Bloom, Pixelate, Invert
* **Live Filter Previews** â€“ Animated thumbnail gallery with wave animations
* **Visual Trimming** â€“ Film-strip view with draggable handles and time tooltips
* **Playhead Tracking** â€“ Real-time video position indicator with time display

### ğŸ“± User Experience
* **Animated Loading States** â€“ Braille spinner and shimmer effects
* **Spring Animations** â€“ Cascading filter animations and responsive interactions
* **Time Display** â€“ Precise MM:SS.d format timers throughout the interface
* **Debug Tools** â€“ Developer menu for testing and animation triggers

### ğŸ’¾ Export & Sharing
* **GIF Export** â€“ Configurable frame-rate (6, 12, 24, 30 FPS) & custom duration
* **Video Export** â€“ Save filtered videos with applied effects
* **Multiple Output Options** â€“ Save to Photos, copy to clipboard, or share
* **Background Processing** â€“ Dedicated `VideoProcessingService` for smooth performance

### ğŸ—ï¸ Architecture
* **MVVM Pattern** â€“ Clean separation with `VideoEditorViewModel`
* **Swift 6 Ready** â€“ Full concurrency support with async/await and `@MainActor`
* **Modular Design** â€“ Reusable components and services
* **Comprehensive Testing** â€“ Unit & UI tests that run on-device / Simulator

---

## ğŸ› Architecture

```mermaid
flowchart TD
    A[ContentView] -->|Observes| B(VideoEditorViewModel)
    B -->|Delegates to| C(VideoProcessingService)
    C -->|Uses| D{VideoFilterManager}
    B -->|Exports via| E(VideoExporter)
    B -->|Imports from| F(VideoImporter)
    B -->|Captures with| G(CameraKitView)
    A -->|Contains| H[VideoTrimmerView]
    A -->|Contains| I[FilterPickerView]
    A -->|Contains| J[NoVideoPlaceholderView]
    A -->|Shows| K[BrailleSpinnerView]
    A -->|Debug| L[DebugMenu]
```

### Component Overview

* **Views (SwiftUI)**
  * `ContentView` â€“ Main interface with video preview and controls
  * `VideoTrimmerView` â€“ Film strip with draggable trim handles and tooltips
  * `FilterPickerView` â€“ Animated filter gallery with live thumbnails
  * `NoVideoPlaceholderView` â€“ Empty state with animated call-to-action
  * `BrailleSpinnerView` â€“ Custom loading animation
  * `DebugMenu` â€“ Developer tools and animation triggers

* **ViewModels & Services**
  * `VideoEditorViewModel` â€“ Main state management with `@MainActor` safety
  * `VideoProcessingService` â€“ Background video processing and thumbnail generation

* **Core Utilities**
  * `VideoFilterManager` â€“ Core Image filter implementations
  * `VideoExporter` â€“ Export to video/GIF with background processing
  * `VideoImporter` â€“ PHPicker integration for media selection
  * `CameraKitView` & `VideoCaptureView` â€“ Video recording capabilities
  * `AVAsset+SafeLoad` â€“ Safe async property loading extension

---

## ğŸš€ Getting Started

### Prerequisites

* Xcode 16 (or newer â€“ project uses Swift 5.9 & Swift 6 warnings)
* macOS 15.5 or newer

### Clone & Open

```bash
git clone https://github.com/arach/Loopa.git
cd Loopa
open Loopa.xcodeproj
```

### Run in Simulator

1. Select the *Loopa* scheme.  
2. Choose an iOS 16+ simulator (e.g. *iPhone 16*).  
3. Hit **âŒ˜R**.

---

## ğŸ§© Swift Package Manager

`LoopaCore` is an SPM library target that contains all reusable logic.  This enables:

* Importing Loopa features into other apps.
* `swift build` / `swift test` for macOS-compatible code.

> Note: UI-centric files are conditionally compiled with `#if canImport(UIKit)` and excluded from macOS builds.

---

## ğŸ”§ Building & Testing from CLI

### Build App

```bash
xcodebuild build \
  -scheme Loopa \
  -destination 'platform=iOS Simulator,name=iPhone 16'
```

### Run Unit & UI Tests

```bash
xcodebuild test \
  -scheme Loopa \
  -destination 'platform=iOS Simulator,name=iPhone 16'
```

### Swift Package Tests (macOS-only parts)

```bash
swift test
```

---

## ğŸ“ Project Structure

```
Loopa/
â”œâ”€ Loopa/                    # App target (SwiftUI views, iOS-only)
â”‚  â”œâ”€ ContentView.swift         # Main interface
â”‚  â”œâ”€ VideoEditorViewModel.swift # State management
â”‚  â”œâ”€ VideoProcessingService.swift # Background processing
â”‚  â”œâ”€ VideoFilterManager.swift   # Core Image filters
â”‚  â”œâ”€ VideoExporter.swift       # Export functionality
â”‚  â”œâ”€ VideoImporter.swift       # Photo picker integration
â”‚  â”œâ”€ CameraKitView.swift       # Video recording
â”‚  â”œâ”€ VideoCaptureView.swift    # Camera interface
â”‚  â”œâ”€ VideoTrimmerView.swift    # Film strip editor
â”‚  â”œâ”€ FilterPickerView.swift    # Filter gallery (in ContentView)
â”‚  â”œâ”€ NoVideoPlaceholderView.swift # Empty state
â”‚  â”œâ”€ BrailleSpinnerView.swift  # Loading animation
â”‚  â”œâ”€ DebugMenu.swift           # Developer tools
â”‚  â”œâ”€ AVAsset+SafeLoad.swift    # Async extensions
â”‚  â”œâ”€ Assets.xcassets/          # Images and colors
â”‚  â”‚  â””â”€ film_sprockets.imageset/ # Trimmer background
â”‚  â””â”€ Media/                    # Asset resources
â”‚     â””â”€ film_sprockets.png
â”œâ”€ Media/                    # Test media files
â”‚  â””â”€ coffee.mov
â”œâ”€ LoopaTests/               # XCTest unit tests (+ resources)
â”‚  â”œâ”€ LoopaTests.swift
â”‚  â””â”€ test_video.mov
â”œâ”€ LoopaUITests/             # UI test target
â”œâ”€ Package.swift             # SPM manifest (LoopaCore)
â”œâ”€ CLAUDE.md                 # AI assistant context
â””â”€ README.md
```

---

## ğŸ¤ Contributing

1. Fork the repo & create your branch (`git checkout -b feature/AmazingFeature`).
2. Commit your changes (`git commit -m 'Add some AmazingFeature'`).
3. Push to the branch (`git push origin feature/AmazingFeature`).
4. Open a Pull Request.

---

## ğŸ“„ License

Licensed under the MIT License â€“ see [`LICENSE`](LICENSE) for details. 